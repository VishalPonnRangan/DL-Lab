{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKTYdXTfCUIQ"
   },
   "outputs": [],
   "source": [
    "#XOR using perceptron\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# XOR input and output\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Build a simple multilayer perceptron model\n",
    "model = Sequential([\n",
    "    Dense(2, input_dim=2, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on XOR data\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Predict on new data\n",
    "predictions = model.predict(X)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2aMDwaBImV9"
   },
   "outputs": [],
   "source": [
    "#Character and Digit Recognition\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Generate synthetic character and digit data\n",
    "data_size = 1000\n",
    "characters = np.random.choice(list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"), size=data_size)\n",
    "digits = np.random.choice(range(10), size=data_size)\n",
    "\n",
    "# Concatenate character and digit features\n",
    "features = np.column_stack((characters, digits))\n",
    "\n",
    "# Label encode characters\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(characters)\n",
    "\n",
    "# One-hot encode digits\n",
    "digits_one_hot = np.eye(10)[digits]\n",
    "\n",
    "# Concatenate features and one-hot encoded digits\n",
    "features = np.column_stack((features, digits_one_hot))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(17,), activation='relu'),\n",
    "    Dense(len(np.unique(labels)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on character and digit data\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Cto1wb7JF4f"
   },
   "outputs": [],
   "source": [
    "#X-Ray image autoencoders\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Generate synthetic X-ray image data\n",
    "data_size = 100\n",
    "image_height, image_width = 64, 64\n",
    "images = np.random.rand(data_size, image_height, image_width)\n",
    "\n",
    "# Build an autoencoder model\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(image_height, image_width, 1)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Preprocess images for autoencoder\n",
    "images = images.reshape(data_size, image_height, image_width, 1)\n",
    "\n",
    "# Train the autoencoder\n",
    "model.fit(images, images, epochs=10, batch_size=10, shuffle=True)\n",
    "\n",
    "# Visualize original and reconstructed images\n",
    "reconstructed_images = model.predict(images)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(images[i].reshape(image_height, image_width), cmap='gray')\n",
    "    plt.title('Original')\n",
    "\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.imshow(reconstructed_images[i].reshape(image_height, image_width), cmap='gray')\n",
    "    plt.title('Reconstructed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSRzxSNCJaBc"
   },
   "outputs": [],
   "source": [
    "#Speechrecognition\n",
    "import speech_recognition as sr\n",
    "def speech_recognition_example():\n",
    "  recognizer = sr.Recognizer()\n",
    "  with sr.Microphone() as source:\n",
    "    print(\"Say something:\")\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    audio = recognizer.listen(source, timeout=5)\n",
    "  try:\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    print(f\"You said: {text}\")\n",
    "  except sr.UnknownValueError:\n",
    "    print(\"Speech recognition could not understand audio\")\n",
    "  except sr.RequestError as e:\n",
    "    print(f\"Could not request results from Google Web Speech API; {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  speech_recognition_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyJsEKhYKMoZ"
   },
   "outputs": [],
   "source": [
    "#TrafficAnalysis\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Generate synthetic traffic data\n",
    "data_size = 1000\n",
    "images = np.random.rand(data_size, 64, 64, 3)  # Placeholder for traffic images\n",
    "labels_object = np.random.choice(['car', 'truck', 'bus'], size=data_size)\n",
    "labels_class = np.random.choice(['normal', 'congested'], size=data_size)\n",
    "\n",
    "# Label encode object labels\n",
    "label_encoder_object = LabelEncoder()\n",
    "labels_object_encoded = label_encoder_object.fit_transform(labels_object)\n",
    "\n",
    "# Label encode class labels\n",
    "label_encoder_class = LabelEncoder()\n",
    "labels_class_encoded = label_encoder_class.fit_transform(labels_class)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train_object, y_test_object, y_train_class, y_test_class = train_test_split(\n",
    "    images, labels_object_encoded, labels_class_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build a CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(np.unique(labels_object_encoded)), activation='softmax'),  # Object detection\n",
    "    Dense(len(np.unique(labels_class_encoded)), activation='softmax')  # Traffic classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, [y_train_object, y_train_class], epochs=10, validation_data=(X_test, [y_test_object, y_test_class]))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_object, accuracy_class = model.evaluate(X_test, [y_test_object, y_test_class])[3:5]\n",
    "print(f\"Object Detection Test Accuracy: {accuracy_object}\")\n",
    "print(f\"Traffic Classification Test Accuracy: {accuracy_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-ZqX0T7Ko8-"
   },
   "outputs": [],
   "source": [
    "#OnlineFraudDetection\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic market data\n",
    "data_size = 1000\n",
    "features = np.random.rand(data_size, 10)  # Placeholder for market features\n",
    "labels = np.random.choice([0, 1], size=data_size, p=[0.95, 0.05])  # Simulate fraud rate of 5%\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build an Isolation Forest model for fraud detection\n",
    "model = IsolationForest(contamination=0.05)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "predictions[predictions == 1] = 0  # Convert normal instances to 0 and fraud instances to -1\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHvOA4ABK_kF"
   },
   "outputs": [],
   "source": [
    "#Image Augmentation\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Generate synthetic image data\n",
    "data_size = 1000\n",
    "images = np.random.rand(data_size, 64, 64)  # Placeholder for images\n",
    "\n",
    "# Flatten images for RBM\n",
    "images_flat = images.reshape(data_size, -1)\n",
    "\n",
    "# Scale pixel values to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "images_flat = scaler.fit_transform(images_flat)\n",
    "\n",
    "# Build a deep RBM model\n",
    "model = BernoulliRBM(n_components=100, learning_rate=0.01, n_iter=10, random_state=0, verbose=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(images_flat)\n",
    "\n",
    "# Transform images using the trained model\n",
    "images_augmented = model.transform(images_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHYNhPWHLKTR"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic sentiment data\n",
    "data_size = 1000\n",
    "texts = [\"good\", \"bad\", \"neutral\", \"excellent\"] * (data_size // 4)\n",
    "labels = np.random.choice([0, 1], size=data_size, p=[0.8, 0.2])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=50)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=10,padding='post')\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=50, output_dim=100, input_length=10),\n",
    "    LSTM(100),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0ECCILxO20V"
   },
   "outputs": [],
   "source": [
    "#NumberPlate Analysis\n",
    "import cv2\n",
    "from openalpr import Alpr\n",
    "\n",
    "# Set the OpenALPR configuration\n",
    "alpr = Alpr(\"us\", \"/etc/openalpr/openalpr.conf\", \"/usr/share/openalpr/runtime_data\")\n",
    "\n",
    "# Check if the OpenALPR configuration is loaded successfully\n",
    "if not alpr.is_loaded():\n",
    "    print(\"Error loading OpenALPR configuration\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the pre-trained number plate recognition model\n",
    "alpr.set_top_n(1)  # Set to 1 to get the top result only\n",
    "\n",
    "# Video capture from webcam (0) or video file path\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture video frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Detect number plates\n",
    "    results = alpr.recognize_ndarray(frame)\n",
    "\n",
    "    # Display the results on the frame\n",
    "    for plate in results['results']:\n",
    "        plate_str = plate['plate']\n",
    "        confidence = plate['confidence']\n",
    "        for candidate in plate['candidates']:\n",
    "            plate_str = candidate['plate']\n",
    "            confidence = candidate['confidence']\n",
    "\n",
    "        cv2.putText(frame, f\"Plate: {plate_str} (Confidence: {confidence:.2f})\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Number Plate Recognition', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Unload the OpenALPR library\n",
    "alpr.unload()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

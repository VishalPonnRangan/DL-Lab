{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXWco_jZRZsm"
      },
      "outputs": [],
      "source": [
        "#XOR\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "def sigmoid(z):\n",
        "return 1 / (1 + np.exp(-z))\n",
        "def initialize_params(input_features, hidden_neurons, output_features):\n",
        "W1 = np.random.randn(hidden_neurons, input_features)\n",
        "W2 = np.random.randn(output_features, hidden_neurons)\n",
        "b1 = np.zeros((hidden_neurons, 1))\n",
        "b2 = np.zeros((output_features, 1))\n",
        "return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
        "def forward_propagation(X, Y, params):\n",
        "m = X.shape[1]\n",
        "Z1 = np.dot(params[\"W1\"], X) + params[\"b1\"]\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(params[\"W2\"], A1) + params[\"b2\"]\n",
        "A2 = sigmoid(Z2)\n",
        "logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), (1 - Y))\n",
        "cost = -np.sum(logprobs) / m\n",
        "return cost, (Z1, A1, params[\"W1\"], params[\"b1\"], Z2, A2, params[\"W2\"], params[\"b2\"]),\n",
        "A2\n",
        "def backward_propagation(X, Y, cache):\n",
        "m = X.shape[1]\n",
        "Z1, A1, W1, b1, Z2, A2, W2, b2 = cache\n",
        "dZ2 = A2 - Y\n",
        "dW2 = np.dot(dZ2, A1.T) / m\n",
        "db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
        "dA1 = np.dot(W2.T, dZ2)\n",
        "dZ1 = np.multiply(dA1, A1 * (1 - A1))\n",
        "dW1 = np.dot(dZ1, X.T) / m\n",
        "db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
        "return {\"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2, \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n",
        "def update_params(params, gradients, learning_rate):\n",
        "params[\"W1\"] -= learning_rate * gradients[\"dW1\"]\n",
        "params[\"W2\"] -= learning_rate * gradients[\"dW2\"]\n",
        "params[\"b1\"] -= learning_rate * gradients[\"db1\"]\n",
        "params[\"b2\"] -= learning_rate * gradients[\"db2\"]\n",
        "return params\n",
        "X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]]) # XOR input\n",
        "Y = np.array([[0, 1, 1, 0]]) # XOR output\n",
        "hidden_neurons, input_features, output_features = 2, X.shape[0], Y.shape[0]\n",
        "params = initialize_params(input_features, hidden_neurons, output_features)\n",
        "epochs, learning_rate = 100000, 0.01\n",
        "losses = np.zeros((epochs, 1))\n",
        "for i in range(epochs):\n",
        "losses[i, 0], cache, A2 = forward_propagation(X, Y, params)\n",
        "gradients = backward_propagation(X, Y, cache)\n",
        "params = update_params(params, gradients, learning_rate)\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"EPOCHS\")\n",
        "plt.ylabel(\"Loss value\")\n",
        "plt.show()\n",
        "X = np.array([[1, 1, 0, 0], [0, 1, 0, 1]]) # XOR input\n",
        "cost, _, A2 = forward_propagation(X, Y, params)\n",
        "prediction = (A2 > 0.5) * 1.0\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Digit Recognition\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "model = keras.Sequential([\n",
        "keras.layers.Flatten(input_shape=(28, 28)),\n",
        "keras.layers.Dense(128, activation='relu'),\n",
        "keras.layers.Dropout(0.2),\n",
        "keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "predictions = model.predict(x_test)\n",
        "num_images_to_display = 5\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_display):\n",
        "plt.subplot(1, num_images_to_display, i + 1)\n",
        "plt.imshow(x_test[i], cmap='gray')\n",
        "plt.title(f\"Predicted: {np.argmax(predictions[i])}\\nActual: {y_test[i]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lckKA2TGTGtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XRay images\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import tempfile\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from skimage.util import random_noise\n",
        "from tqdm import trange\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.data import CacheDataset, DataLoader\n",
        "from monai.networks.nets import AutoEncoder\n",
        "from monai.transforms import (\n",
        "EnsureChannelFirstD,\n",
        "Compose,\n",
        "LoadImageD,\n",
        "RandFlipD,\n",
        "RandRotateD,\n",
        "RandZoomD,\n",
        "ScaleIntensityD,\n",
        "EnsureTypeD,\n",
        "Lambda,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "print_config()\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "set_determinism(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def plot_ims(ims, shape=None, figsize=(10, 10), titles=None):\n",
        "shape = (1, len(ims)) if shape is None else shape\n",
        "plt.subplots(*shape, figsize=figsize)\n",
        "for i, im in enumerate(ims):\n",
        "plt.subplot(*shape, i + 1)\n",
        "im = plt.imread(im) if isinstance(im, str) else torch.squeeze(im)\n",
        "plt.imshow(im, cmap=\"gray\")\n",
        "if titles is not None:\n",
        "plt.title(titles[i])\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)\n",
        "resource = \"https://github.com/Project-MONAI/MONAI-extra-test\n",
        "data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
        "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
        "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
        "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
        "if not os.path.exists(data_dir):\n",
        "download_and_extract(resource, compressed_file, root_dir, md5)\n",
        "scan_type = \"Hand\"\n",
        "im_dir = os.path.join(data_dir, scan_type)\n",
        "all_filenames = [os.path.join(im_dir, filename) for filename in os.listdir(im_dir)]\n",
        "random.shuffle(all_filenames)\n",
        "rand_images = np.random.choice(all_filenames, 8, replace=False)\n",
        "plot_ims(rand_images, shape=(2, 4))\n",
        "test_frac = 0.2\n",
        "num_test = int(len(all_filenames) * test_frac)\n",
        "num_train = len(all_filenames) - num_test\n",
        "train_datadict = [{\"im\": fname} for fname in all_filenames[:num_train]]\n",
        "test_datadict = [{\"im\": fname} for fname in all_filenames[-num_test:]]\n",
        "NoiseLambda = Lambda(\n",
        "lambda d: {\n",
        "\"orig\": d[\"im\"],\n",
        "\"gaus\": torch.tensor(random_noise(d[\"im\"], mode=\"gaussian\"), dtype=torch.float32),\n",
        "\"s&p\": torch.tensor(random_noise(d[\"im\"], mode=\"s&p\", salt_vs_pepper=0.1)),\n",
        "}\n",
        ")\n",
        "train_transforms = Compose(\n",
        "[\n",
        "LoadImageD(keys=[\"im\"]),\n",
        "EnsureChannelFirstD(keys=[\"im\"]),\n",
        "ScaleIntensityD(keys=[\"im\"]),\n",
        "RandRotateD(keys=[\"im\"], range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
        "RandFlipD(keys=[\"im\"], spatial_axis=0, prob=0.5),\n",
        "RandZoomD(keys=[\"im\"], min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "EnsureTypeD(keys=[\"im\"]),\n",
        "NoiseLambda,\n",
        "]\n",
        ")\n",
        "test_transforms = Compose(\n",
        "[\n",
        "LoadImageD(keys=[\"im\"]),\n",
        "EnsureChannelFirstD(keys=[\"im\"]),\n",
        "ScaleIntensityD(keys=[\"im\"]),\n",
        "EnsureTypeD(keys=[\"im\"]),\n",
        "NoiseLambda,\n",
        "]\n",
        ")\n",
        "batch_size = 300\n",
        "num_workers = 10\n",
        "train_ds = CacheDataset(train_datadict, train_transforms, num_workers=num_workers)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "num_workers=num_workers)\n",
        "test_ds = CacheDataset(test_datadict, test_transforms, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True,\n",
        "num_workers=num_workers)\n",
        "def get_single_im(ds):\n",
        "loader = torch.utils.data.DataLoader(ds, batch_size=1, num_workers=10, shuffle=True)\n",
        "itera = iter(loader)\n",
        "return next(itera)\n",
        "data = get_single_im(train_ds)\n",
        "plot_ims([data[\"orig\"], data[\"gaus\"], data[\"s&p\"]], titles=[\"orig\", \"Gaussian\", \"s&p\"])\n",
        "def train(dict_key_for_training, max_epochs=10, learning_rate=1e-3):\n",
        "model = AutoEncoder(\n",
        "spatial_dims=2,\n",
        "in_channels=1,\n",
        "out_channels=1,\n",
        "channels=(4, 8, 16, 32),\n",
        "strides=(2, 2, 2, 2),\n",
        ").to(device)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "epoch_loss_values = []\n",
        "t = trange(max_epochs, desc=f\"{dict_key_for_training} -- epoch 0, avg loss: inf\",\n",
        "leave=True)\n",
        "for epoch in t:\n",
        "model.train()\n",
        "epoch_loss = 0\n",
        "step = 0\n",
        "for batch_data in train_loader:\n",
        "step += 1\n",
        "inputs = batch_data[dict_key_for_training].to(device)\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "loss = loss_function(outputs, batch_data[\"orig\"].to(device))\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "epoch_loss += loss.item()\n",
        "epoch_loss /= step\n",
        "epoch_loss_values.append(epoch_loss)\n",
        "t.set_description(f\"{dict_key_for_training} -- epoch {epoch + 1}\" + f\", average loss:\n",
        "{epoch_loss:.4f}\")\n",
        "return model, epoch_loss_values\n",
        "max_epochs = 50\n",
        "training_types = [\"orig\", \"gaus\", \"s&p\"]\n",
        "models = []\n",
        "epoch_losses = []\n",
        "for training_type in training_types:\n",
        "model, epoch_loss = train(training_type, max_epochs=max_epochs)\n",
        "models.append(model)\n",
        "epoch_losses.append(epoch_loss)\n",
        "plt.figure()\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "for y, label in zip(epoch_losses, training_types):\n",
        "x = list(range(1, len(y) + 1))\n",
        "(line,) = plt.plot(x, y)\n",
        "line.set_label(label)\n",
        "plt.legend()\n",
        "data = get_single_im(test_ds)\n",
        "recons = []\n",
        "for model, training_type in zip(models, training_types):\n",
        "im = data[training_type]\n",
        "recon = model(im.to(device)).detach().cpu()\n",
        "recons.append(recon)\n",
        "plot_ims(\n",
        "[data[\"orig\"], data[\"gaus\"], data[\"s&p\"]] + recons,\n",
        "titles=[\"orig\", \"Gaussian\", \"S&P\"] + [\"recon w/\\n\" + x for x in training_types],\n",
        "shape=(2, len(training_types)),\n",
        ")\n",
        "def inference(dict_key_for_training, trained_model):\n",
        "model = trained_model\n",
        "model.eval()\n",
        "im = data[dict_key_for_training]\n",
        "recon = model(im.to(device)).detach().cpu()\n",
        "return recon\n",
        "reconstructions = []\n",
        "for trained_model, training_type in zip(models, training_types):\n",
        "recon = inference(training_type, trained_model)\n",
        "reconstructions.append(recon)\n",
        "plot_ims(\n",
        "[data[\"orig\"], data[\"gaus\"], data[\"s&p\"]] + reconstructions,\n",
        "titles=[\"orig\", \"Gaussian\", \"S&P\"] + [\"recon w/\\n\" + x for x in training_types],\n",
        "shape=(2, len(training_types)),\n",
        ")"
      ],
      "metadata": {
        "id": "O7i6zmGXTKj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Speech Recognition\n",
        "import speech_recognition as sr\n",
        "def speech_recognition_example():\n",
        "recognizer = sr.Recognizer()\n",
        "with sr.Microphone() as source:\n",
        "print(\"Say something:\")\n",
        "recognizer.adjust_for_ambient_noise(source)\n",
        "audio = recognizer.listen(source, timeout=5)\n",
        "try:\n",
        "text = recognizer.recognize_google(audio)\n",
        "print(f\"You said: {text}\")\n",
        "except sr.UnknownValueError:\n",
        "print(\"Speech recognition could not understand audio\")\n",
        "except sr.RequestError as e:\n",
        "print(f\"Could not request results from Google Web Speech API; {e}\")\n",
        "if __name__ == \"__main__\":\n",
        "speech_recognition_example()"
      ],
      "metadata": {
        "id": "8JhqgqBvTkYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Traffic Analysis\n",
        "import cv2\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from tracker import EuclideanDistTracker\n",
        "cap = cv2.VideoCapture(\"bridge.mp4\")\n",
        "input_size = 320\n",
        "tracker = EuclideanDistTracker()\n",
        "confThreshold = 0.2\n",
        "nmsThreshold = 0.2\n",
        "font_color = (0, 0, 255)\n",
        "font_size = 0.5\n",
        "font_thickness = 2\n",
        "middle_line_position = 225\n",
        "up_line_position = middle_line_position - 15\n",
        "down_line_position = middle_line_position + 15\n",
        "classesFile = \"coco.names\"\n",
        "classNames = open(classesFile).read().strip().split('\\n')\n",
        "print(classNames)\n",
        "print(len(classNames))\n",
        "required_class_index = [2, 3, 5, 7]\n",
        "detected_classNames = []\n",
        "modelConfiguration = 'yolov3-320.cfg'\n",
        "modelWeights = 'yolov3-320.weights'\n",
        "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "np.random.seed(42)\n",
        "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
        "def find_center(x, y, w, h):\n",
        "x1 = int(w / 2)\n",
        "y1 = int(h / 2)\n",
        "cx = x + x1\n",
        "cy = y + y1\n",
        "return cx, cy\n",
        "temp_up_list = []\n",
        "temp_down_list = []\n",
        "up_list = [0, 0, 0, 0]\n",
        "down_list = [0, 0, 0, 0]\n",
        "def count_vehicle(box_id, img):\n",
        "x, y, w, h, id, index = box_id\n",
        "center = find_center(x, y, w, h)\n",
        "ix, iy = center\n",
        "if (iy > up_line_position) and (iy < middle_line_position):\n",
        "if id not in temp_up_list:\n",
        "temp_up_list.append(id)\n",
        "elif iy < down_line_position and iy > middle_line_position:\n",
        "if id not in temp_down_list:\n",
        "temp_down_list.append(id)\n",
        "elif iy < up_line_position:\n",
        "if id in temp_down_list:\n",
        "temp_down_list.remove(id)\n",
        "up_list[index] = up_list[index] + 1\n",
        "elif iy > down_line_position:\n",
        "if id in temp_up_list:\n",
        "temp_up_list.remove(id)\n",
        "down_list[index] = down_list[index] + 1\n",
        "cv2.circle(img, center, 2, (0, 0, 255), -1)\n",
        "def postProcess(outputs, img):\n",
        "global detected_classNames\n",
        "height, width = img.shape[:2]\n",
        "211720243052\n",
        "boxes = []\n",
        "classIds = []\n",
        "confidence_scores = []\n",
        "detection = []\n",
        "for output in outputs:\n",
        "for det in output:\n",
        "scores = det[5:]\n",
        "classId = np.argmax(scores)\n",
        "confidence = scores[classId]\n",
        "if classId in required_class_index:\n",
        "if confidence > confThreshold:\n",
        "w, h = int(det[2] * width), int(det[3] * height)\n",
        "x, y = int((det[0] * width) - w / 2), int((det[1] * height) - h / 2)\n",
        "boxes.append([x, y, w, h])\n",
        "classIds.append(classId)\n",
        "confidence_scores.append(float(confidence)\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
        "for i in indices.flatten():\n",
        "x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
        "color = [int(c) for c in colors[classIds[i]]\n",
        "name = classNames[classIds[i]]\n",
        "detected_classNames.append(name)\n",
        "cv2.putText(img, f'{name.upper()} {int(confidence_scores[i] * 100)}%',\n",
        "(x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
        "detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
        "boxes_ids = tracker.update(detection)\n",
        "for box_id in boxes_ids:\n",
        "count_vehicle(box_id, img)\n",
        "def realTime():\n",
        "while True:\n",
        "success, img = cap.read()\n",
        "img = cv2.resize(img, (0, 0), None, 0.5, 0.5)\n",
        "ih, iw, channels = img.shape\n",
        "blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1,\n",
        "crop=False)\n",
        "net.setInput(blob)\n",
        "layersNames = net.getLayerNames()\n",
        "outputNames = [(layersNames[i - 1]) for i in net.getUnconnectedOutLayers()]\n",
        "outputs = net.forward(outputNames)\n",
        "postProcess(outputs, img)\n",
        "cv2.line(img, (0, middle_line_position), (iw, middle_line_position), (255, 0, 255), 2)\n",
        "cv2.line(img, (0, up_line_position), (iw, up_line_position), (0, 0, 255), 2)\n",
        "cv2.line(img, (0, down_line_position), (iw, down_line_position), (0, 0, 255), 2)\n",
        "cv2.putText(img, \"Up\", (110, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size,\n",
        "font_color, font_thickness)\n",
        "cv2.putText(img, \"Down\", (160, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size,\n",
        "font_color, font_thickness)\n",
        "cv2.putText(img, \"Car: \" + str(up_list[0]) + \" \" + str(down_list[0]), (20, 40),\n",
        "cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
        "cv2.putText(img, \"Motorbike: \" + str(up_list[1]) + \" \" + str(down_list[1]), (20, 60),\n",
        "cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
        "cv2.putText(img, \"Bus: \" + str(up_list[2]) + \" \" + str(down_list[2]), (20, 80),\n",
        "cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
        "cv2.putText(img, \"Truck: \" + str(up_list[3]) + \" \" + str(down_list[3]), (20, 100),\n",
        "cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
        "cv2.imshow('Output', img)\n",
        "if cv2.waitKey(1) == ord('q'):\n",
        "break\n",
        "with open(\"data.csv\", 'w') as f1:\n",
        "cwriter = csv.writer(f1)\n",
        "cwriter.writerow(['Direction', 'car', 'motorbike', 'bus', 'truck'])\n",
        "up_list.insert(0, \"Up\")\n",
        "down_list.insert(0, \"Down\")\n",
        "cwriter.writerow(up_list)\n",
        "cwriter.writerow(down_list)\n",
        "print(\"Data saved at 'data.csv'\")\n",
        "f1.close()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "if __name__ == '__main__':\n",
        "realTime()"
      ],
      "metadata": {
        "id": "utnqExt7TpoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Online fraud detect\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report\n",
        "dataset = pd.read_csv('share_market_data.csv')\n",
        "X = dataset.drop('Target', axis=1)\n",
        "y = dataset['Target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "model = IsolationForest(contamination=0.1, random_state=1)\n",
        "model.fit(X_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x == -1 else 0 for x in y_pred]\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "68g5hu2aT2T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image Augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=45,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='constant', cval=125)\n",
        "x = io.imread('msd_abd/msd/msd.jpg')\n",
        "x = x.reshape((1, ) + x.shape)\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=16, save_to_dir='augmented', save_prefix='aug',\n",
        "save_format='png'):\n",
        "i += 1\n",
        "if i > 20:\n",
        "break\n",
        "SIZE = 128\n",
        "dataset = []\n",
        "image_directory = 'test_folder/'\n",
        "my_images = os.listdir(image_directory)\n",
        "for i, image_name in enumerate(my_images):\n",
        "if image_name.split('.')[1] == 'jpg':\n",
        "image = io.imread(image_directory + image_name)\n",
        "image = Image.fromarray(image, 'RGB')\n",
        "image = image.resize((SIZE, SIZE))\n",
        "dataset.append(np.array(image))\n",
        "x = np.array(dataset)\n",
        "i = 0\n",
        "for batch in datagen.flow_from_directory(\n",
        "directory='msd_abd/',\n",
        "batch_size=16,\n",
        "target_size=(256, 256),\n",
        "color_mode=\"rgb\",\n",
        "save_to_dir='augmented',\n",
        "save_prefix='aug',\n",
        "save_format='png'):\n",
        "i += 1\n",
        "if i > 31:\n",
        "break"
      ],
      "metadata": {
        "id": "ZTZf2cFrT_2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "data = pd.read_csv('../input/Sentiment.csv')\n",
        "data = data[['text', 'sentiment']]\n",
        "data = data[data.sentiment != \"Neutral\"]\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X)\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim, input_length=X.shape[1])\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "Y = pd.get_dummies(data['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "batch_size = 32\n",
        "model.fit(X_train, Y_train, epochs=7, batch_size=batch_size, verbose=2)\n",
        "validation_size = 1500\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)\n",
        "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "result = model.predict(X_validate[x].reshape(1, X_test.shape[1]), batch_size=1,\n",
        "verbose=2)[0]\n",
        "if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "if np.argmax(Y_validate[x]) == 0:\n",
        "neg_correct += 1\n",
        "else:\n",
        "pos_correct += 1\n",
        "if np.argmax(Y_validate[x]) == 0:\n",
        "neg_cnt += 1\n",
        "else:\n",
        "pos_cnt += 1\n",
        "twt = ['Meetings: Because none of us is as dumb as all of us.']\n",
        "twt = tokenizer.texts_to_sequences(twt)\n",
        "twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n",
        "sentiment = model.predict(twt, batch_size=1, verbose=2)[0]\n",
        "if np.argmax(sentiment) == 0:\n",
        "print(\"negative\")\n",
        "elif np.argmax(sentiment) == 1:\n",
        "print(\"positive\")"
      ],
      "metadata": {
        "id": "4HEOeXkQUJ3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H6pijHAJUhmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}